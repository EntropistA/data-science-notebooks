{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = data.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images /  255.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flatten changes a 2D 28x28 input into a series of numeric values (1D array)\n",
    "**layers.Flatten(input_shape=(28, 28))**\n",
    "\n",
    "_Hidden layer_ (between input, output, unseen by caller) made of 128 neurons with randomly initialized parameters\n",
    "layers.Dense(128, activation=tf.nn.relu)\n",
    "\n",
    "too many neurons - long time of learning, _overfitting_ - bad with new data\n",
    "too few neurons - underfitting\n",
    "\n",
    "activation - a function which runs on each neuron in a layer\n",
    "relu is a very common one in the middle\n",
    "f(x) = max(0, x)\n",
    "\n",
    "Output layer\n",
    "layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "softmax function converts a vector of K values into vector of K probability values summing to 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of large size of the set (60_000 elements) we are using adam optimizer which performs faster than standard SGD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2789 - accuracy: 0.8972\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2653 - accuracy: 0.9013\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2543 - accuracy: 0.9052\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2451 - accuracy: 0.9094\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2359 - accuracy: 0.9124\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2285 - accuracy: 0.9139\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2198 - accuracy: 0.9174\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2149 - accuracy: 0.9194\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2068 - accuracy: 0.9231\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2033 - accuracy: 0.9237\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1952 - accuracy: 0.9269\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1919 - accuracy: 0.9289\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1871 - accuracy: 0.9289\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1816 - accuracy: 0.9310\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1763 - accuracy: 0.9330\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1729 - accuracy: 0.9341\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1670 - accuracy: 0.9371\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1651 - accuracy: 0.9381\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1607 - accuracy: 0.9400\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1577 - accuracy: 0.9399\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1536 - accuracy: 0.9432\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1493 - accuracy: 0.9441\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1482 - accuracy: 0.9445\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1432 - accuracy: 0.9462\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1412 - accuracy: 0.9471\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1372 - accuracy: 0.9480\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1355 - accuracy: 0.9489\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1316 - accuracy: 0.9503\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1295 - accuracy: 0.9511\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1280 - accuracy: 0.9515\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1243 - accuracy: 0.9530\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1229 - accuracy: 0.9540\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1220 - accuracy: 0.9548\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1189 - accuracy: 0.9554\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1145 - accuracy: 0.9576\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1140 - accuracy: 0.9572\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1105 - accuracy: 0.9581\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1092 - accuracy: 0.9596\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1090 - accuracy: 0.9594\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1054 - accuracy: 0.9605\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1031 - accuracy: 0.9611\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1011 - accuracy: 0.9617\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1015 - accuracy: 0.9619\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0997 - accuracy: 0.9623\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0952 - accuracy: 0.9642\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0953 - accuracy: 0.9645\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0932 - accuracy: 0.9648\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0917 - accuracy: 0.9658\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0907 - accuracy: 0.9669\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0908 - accuracy: 0.9657\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x156d544dbe0>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.5694427490234375, 0.8844000101089478]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lower accuracy on test images comes naturally because the model has now yet seen test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 871us/step\n",
      "[3.1065554e-06 2.3732476e-07 1.1244783e-06 2.0740361e-09 4.0761321e-08\n",
      " 8.2228053e-03 1.9445295e-06 1.9110482e-02 1.8310900e-05 9.7264194e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    model_choice_value = max(classifications[i])\n",
    "    model_choice = np.where(classifications[i] == model_choice_value)[0][0]\n",
    "\n",
    "    correct_choice = test_labels[i]\n",
    "\n",
    "    if model_choice != correct_choice:\n",
    "        print(i, model_choice, correct_choice)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
